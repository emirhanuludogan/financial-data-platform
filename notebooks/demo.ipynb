{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9329223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|     Tarih|TP_DK_USD_S_YTL|\n",
      "+----------+---------------+\n",
      "|2024-01-02|        29.4913|\n",
      "|2024-01-03|        29.7209|\n",
      "|2024-01-04|         29.793|\n",
      "|2024-01-05|        29.7988|\n",
      "|2024-01-08|         29.825|\n",
      "+----------+---------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- Tarih: date (nullable = true)\n",
      " |-- TP_DK_USD_S_YTL: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from evds import evdsAPI\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# --- 1. ORTAM VE GÜVENLİK YAPILANDIRMASI ---\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "env_path = os.path.abspath(\"../src/ingestion/.env\")\n",
    "load_dotenv(env_path)\n",
    "API_KEY = os.getenv(\"EVDS_API_KEY\")\n",
    "\n",
    "# --- 2. VERİ EKSTRAKSİYONU (EXTRACT) ---\n",
    "evds = evdsAPI(API_KEY)\n",
    "df_pandas = evds.get_data(\n",
    "    series=[\"TP.DK.USD.S.YTL\"],\n",
    "    startdate=\"01-01-2024\",\n",
    "    enddate=\"31-01-2024\"\n",
    ")\n",
    "\n",
    "# --- 3. SPARK OTURUMU VE VERİ DÖNÜŞÜMÜ ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FinancialDataPlatform_ETL\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Pandas -> Spark Dönüşümü\n",
    "spark_df = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# --- 4. VERİ TEMİZLEME VE TİP DÖNÜŞÜMÜ (DF_FINAL OLUŞTURMA) ---\n",
    "# İşte senin o meşhur 'df_final' değişkenin burada doğuyor:\n",
    "df_cleaned = spark_df.na.drop()\n",
    "df_final = df_cleaned.withColumn(\"Tarih\", to_date(col(\"Tarih\"), \"dd-MM-yyyy\"))\n",
    "\n",
    "# Kontrol\n",
    "df_final.show(5)\n",
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a658c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------+--------------------+\n",
      "|     Tarih|TP_DK_USD_S_YTL|Onceki_Gun_Kur|Gunluk_Degisim_Yuzde|\n",
      "+----------+---------------+--------------+--------------------+\n",
      "|2024-01-02|        29.4913|          NULL|                NULL|\n",
      "|2024-01-03|        29.7209|       29.4913|              0.7785|\n",
      "|2024-01-04|         29.793|       29.7209|              0.2426|\n",
      "|2024-01-05|        29.7988|        29.793|              0.0195|\n",
      "|2024-01-08|         29.825|       29.7988|              0.0879|\n",
      "|2024-01-09|        29.8879|        29.825|              0.2109|\n",
      "|2024-01-10|        29.9361|       29.8879|              0.1613|\n",
      "|2024-01-11|        29.9675|       29.9361|              0.1049|\n",
      "|2024-01-12|        30.0121|       29.9675|              0.1488|\n",
      "|2024-01-15|        30.0704|       30.0121|              0.1943|\n",
      "+----------+---------------+--------------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, col, round\n",
    "\n",
    "# --- 1. ANALİTİK PENCERE YAPILANDIRMASI ---\n",
    "# Veri seti üzerinde zamansal bir sıralama (Window) tanımlıyoruz.\n",
    "# Bu yapı, satırlar arasında 'önceki' (lag) veya 'sonraki' (lead) değerlere erişmemizi sağlar.\n",
    "windowSpec = Window.orderBy(\"Tarih\")\n",
    "\n",
    "# --- 2. ZAMAN SERİSİ ANALİZİ (LAGGING) ---\n",
    "# Bir önceki iş gününün kur değerini yeni bir sütun olarak ekliyoruz.\n",
    "# DE Notu: İlk satırda karşılaştıracak veri olmadığı için bu değer 'null' dönecektir.\n",
    "df_with_lag = df_final.withColumn(\"Onceki_Gun_Kur\", lag(\"TP_DK_USD_S_YTL\").over(windowSpec))\n",
    "\n",
    "# --- 3. İŞ MANTIĞI HESAPLAMA (BUSINESS LOGIC) ---\n",
    "# Günlük kur değişimini yüzde (%) bazında hesaplıyoruz.\n",
    "# Formül: ((Bugünkü Değer - Önceki Değer) / Önceki Değer) * 100\n",
    "df_transformed = df_with_lag.withColumn(\n",
    "    \"Gunluk_Degisim_Yuzde\", \n",
    "    round(((col(\"TP_DK_USD_S_YTL\") - col(\"Onceki_Gun_Kur\")) / col(\"Onceki_Gun_Kur\")) * 100, 4)\n",
    ")\n",
    "\n",
    "# --- 4. ANALİZ DOĞRULAMA ---\n",
    "# İlk 10 satırı inceleyerek hesaplamaların doğruluğunu kontrol ediyoruz.\n",
    "df_transformed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc45195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ETL SÜRECİ TAMAMLANDI ---\n",
      "İşlenmiş veriler 'output_data' klasörüne başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. DEPOLAMA DİZİN YÖNETİMİ ---\n",
    "# Çıktıların proje kök dizininde düzenli bir klasörde toplanmasını sağlıyoruz.\n",
    "output_path = \"output_data\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# --- 2. ÇOKLU FORMATTA KAYIT (MULTI-FORMAT STORAGE) ---\n",
    "# A. CSV Formatı: İş birimleri ve son kullanıcıların kolayca açabilmesi için (İnsan-okunabilir).\n",
    "df_transformed.write.csv(f\"{output_path}/usd_kur_analiz.csv\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# B. Parquet Formatı: Büyük veri sistemleri ve analitik motorlar için (Makine-okunabilir, optimize).\n",
    "# DE Notu: Parquet, kolon bazlı depolama yaparak disk alanından tasarruf ve hızlı sorgulama sağlar.\n",
    "df_transformed.write.parquet(f\"{output_path}/usd_kur_analiz.parquet\", mode=\"overwrite\")\n",
    "\n",
    "print(f\"--- ETL SÜRECİ TAMAMLANDI ---\")\n",
    "print(f\"İşlenmiş veriler '{output_path}' klasörüne başarıyla kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0085e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------+--------------------+\n",
      "|     Tarih|TP_DK_USD_S_YTL|Onceki_Gun_Kur|Gunluk_Degisim_Yuzde|\n",
      "+----------+---------------+--------------+--------------------+\n",
      "|2024-01-02|        29.4913|          NULL|                NULL|\n",
      "|2024-01-03|        29.7209|       29.4913|              0.7785|\n",
      "|2024-01-04|         29.793|       29.7209|              0.2426|\n",
      "|2024-01-05|        29.7988|        29.793|              0.0195|\n",
      "|2024-01-08|         29.825|       29.7988|              0.0879|\n",
      "+----------+---------------+--------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Kaydettiğimiz veriyi klasör yolunu vererek geri okuyoruz\n",
    "check_df = spark.read.parquet(\"output_data/usd_kur_analiz.parquet\")\n",
    "\n",
    "# Eğer tablo geliyorsa verin oradadır!\n",
    "check_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937fb557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
