# ğŸ“ˆ Financial Data Platform (Spark ETL Pipeline)

Bu proje, TCMB (EVDS) Ã¼zerinden alÄ±nan finansal verilerin **PySpark** kullanÄ±larak iÅŸlendiÄŸi, temizlendiÄŸi ve analize hazÄ±r hale getirildiÄŸi uÃ§tan uca bir **Veri MÃ¼hendisliÄŸi (ETL)** pipeline Ã§alÄ±ÅŸmasÄ±dÄ±r.
Proje, kurumsal standartlara uygun olarak Medallion Architecture (Bronze, Silver, Gold) prensipleriyle yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r.

---

## ğŸš€ Ã–ne Ã‡Ä±kan Ã–zellikler

* **Dinamik Veri AlÄ±mÄ±:** TCMB EVDS API entegrasyonu ile gerÃ§ek zamanlÄ±ya yakÄ±n veri Ã§ekimi.
* **BÃ¼yÃ¼k Veri Ä°ÅŸleme:** PySpark kullanarak verinin daÄŸÄ±tÄ±k mimaride iÅŸlenmesi.
* **Feature Engineering:** `Window Functions` ve `Lag` metotlarÄ± kullanÄ±larak gÃ¼nlÃ¼k dÃ¶viz kuru deÄŸiÅŸim yÃ¼zdelerinin hesaplanmasÄ±.
* **Veri Kalitesi (Data Quality):** Eksik verilerin (Null/NaN) temizlenmesi ve ÅŸema (schema) doÄŸrulama sÃ¼reÃ§leri.
* **Ã‡oklu Depolama:** Verilerin hem insan-okunabilir (**CSV**) hem de performans odaklÄ± (**Parquet**) formatlarda kaydedilmesi.
* **ModÃ¼ler:** Script YapÄ±sÄ±: Her ETL adÄ±mÄ±nÄ±n (**Ingestion, Processing, Features**) ayrÄ± ve tek sorumluluÄŸa sahip scriptler tarafÄ±ndan yÃ¶netilmesi.
* **Orkestrasyon:** TÃ¼m sÃ¼recin merkezi bir main.py Ã¼zerinden yÃ¶netilmesi.

---
## ğŸ—ï¸ Veri Mimarisi (Medallion Architecture)

Proje, veriyi ham halinden analitik deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in Ã¼Ã§ katmanlÄ± bir hiyerarÅŸi kullanÄ±r:

Bronze (Raw): EVDS API Ã¼zerinden Ã§ekilen ham verilerin hiÃ§bir deÄŸiÅŸiklik yapÄ±lmadan Parquet formatÄ±nda saklandÄ±ÄŸÄ± katman.

Silver (Processed): Veri tiplerinin dÃ¼zenlendiÄŸi, eksik verilerin (Null/NaN) temizlendiÄŸi ve ÅŸema doÄŸrulamasÄ±nÄ±n yapÄ±ldÄ±ÄŸÄ± katman.

Gold (Analytics): Window Functions ve Lag metotlarÄ± kullanÄ±larak finansal Ã¶zelliklerin (gÃ¼nlÃ¼k deÄŸiÅŸim yÃ¼zdeleri vb.) hesaplandÄ±ÄŸÄ± analitik katman.
---

## ğŸ› ï¸ Teknoloji Stack'i

* **Dil:** Python 3.10.11
* **Framework:** Apache Spark 
* **KÃ¼tÃ¼phaneler:**  Python-dotenv, evds
* **Veri KaynaÄŸÄ±:** TCMB EVDS API
* **Depolama:** Parquet, CSV

---

## ğŸ“‚ Proje YapÄ±sÄ±

â”œâ”€â”€ data/               # Git-ignored (Raw, Silver, Gold katmanlarÄ±)
â”œâ”€â”€ notebooks/          # Veri keÅŸfi ve demo gÃ¶rselleÅŸtirmeler
â”œâ”€â”€ src/                # ETL Pipeline modÃ¼lleri
â”‚   â”œâ”€â”€ ingestion/      # Veri alÄ±mÄ± (Bronze)
â”‚   â”œâ”€â”€ processing.py   # Veri temizleme (Silver)
â”‚   â”œâ”€â”€ features.py     # Ã–zellik mÃ¼hendisliÄŸi (Gold)
â”‚   â””â”€â”€ utils.py        # Spark ve Env yardÄ±mcÄ± fonksiyonlarÄ±
â”œâ”€â”€ .env                # API AnahtarlarÄ± (Git-ignored)
â”œâ”€â”€ .gitignore          # Gereksiz dosyalarÄ±n takibini engelleyen liste
â””â”€â”€ main.py             # Pipeline Orkestrasyon Scripti         # API AnahtarlarÄ± ve hassas veriler (Git-ignored)


------------------------------------------------------------------------------------------------------
âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± sÄ±rasÄ±yla takip edin.

1ï¸âƒ£ Depoyu KlonlayÄ±n

Terminalinizi aÃ§Ä±n ve projeyi bilgisayarÄ±nÄ±za indirin:

git clone https://github.com/emirhanuludogan/financial-data-platform.git
cd financial-data-platform

------------------------------------------------------------------------------------------------------

2ï¸âƒ£ Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin

Spark ve API baÄŸlantÄ±sÄ± iÃ§in gerekli Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± kurun:

pip install pyspark python-dotenv evds


âš ï¸ Python 3.10+ kullanmanÄ±z Ã¶nerilir.
 
 ------------------------------------------------------------------------------------------------------ 
  
3ï¸âƒ£ API YapÄ±landÄ±rmasÄ± (Kritik AdÄ±m)

Projenin kÃ¶k dizininde .env adlÄ± bir dosya oluÅŸturun ve
TCMB (EVDS) Ã¼zerinden aldÄ±ÄŸÄ±nÄ±z API anahtarÄ±nÄ± aÅŸaÄŸÄ±daki formatta ekleyin:

EVDS_API_KEY=buraya_api_anahtarinizi_yazin



ğŸ” .env dosyasÄ± gÃ¼venlik sebebiyle .gitignore iÃ§inde yer almaktadÄ±r.

------------------------------------------------------------------------------------------------------
4ï¸âƒ£ Pipeline'Ä± BaÅŸlatÄ±n

TÃ¼m ETL sÃ¼recini (Ingestion -> Processing -> Features) tek bir komutla Ã§alÄ±ÅŸtÄ±rabilirsiniz:

Bash
python main.py

Alternatif olarak analiz sÃ¼recini gÃ¶zlemlemek iÃ§in notebooks/demo.ipynb dosyasÄ±nÄ± kullanabilirsiniz.

------------------------------------------------------------------------------------------------------